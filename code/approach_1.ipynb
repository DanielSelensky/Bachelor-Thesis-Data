{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "id": "B8YoFI0N2S5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uD1AzP9VnvGM"
      },
      "outputs": [],
      "source": [
        "!pip install PyMuPDF\n",
        "!pip install pymongo\n",
        "!pip install PyDrive2\n",
        "!pip install OpenAI\n",
        "!pip install bert-score\n",
        "!pip install rouge-score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain_community langchain-openai"
      ],
      "metadata": {
        "id": "lpg8i2H_ecJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transforming PDF into individual images:"
      ],
      "metadata": {
        "id": "ebGmMRLoopFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "from PIL import Image\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "YmsPYVMknzK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "vTe8b7ZYoEQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pdf_to_images(pdf_path, output_folder):\n",
        "    # Open the PDF file\n",
        "    pdf_document = fitz.open(pdf_path)\n",
        "    number_of_pages = pdf_document.page_count\n",
        "\n",
        "    # Loop through each page\n",
        "    for page_num in range(number_of_pages):\n",
        "        # Get the page\n",
        "        page = pdf_document.load_page(page_num)\n",
        "        # Render page to an image\n",
        "        pix = page.get_pixmap(dpi=200)\n",
        "\n",
        "        # Convert to a PIL image\n",
        "        img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
        "\n",
        "        # Save the image\n",
        "        img.save(f\"{output_folder}/page_{page_num + 1}.png\")"
      ],
      "metadata": {
        "id": "ZBe7tfpZoaQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_to_images(\"/content/drive/MyDrive/bachelor-thesis/pdfs/01.pdf\", \"/content/drive/MyDrive/bachelor-thesis/output-images\")"
      ],
      "metadata": {
        "id": "A-bf6UXWog2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embedding and storing in MongoDB vector store:"
      ],
      "metadata": {
        "id": "FzfOSocUol2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud init"
      ],
      "metadata": {
        "id": "WQh2YvzUEOXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud auth application-default login"
      ],
      "metadata": {
        "id": "MFyF9KiqDPgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import base64\n",
        "\n",
        "def get_image_embedding(image_url):\n",
        "  google_token = !gcloud auth print-access-token\n",
        "  google_token = google_token[0]\n",
        "\n",
        "  b64img = base64.b64encode(requests.get(image_url).content).decode(\"ascii\")\n",
        "  response = requests.post(\n",
        "      headers={\n",
        "          \"Authorization\": \"Bearer \" + google_token,\n",
        "          \"Content-Type\": \"application/json\"\n",
        "          },\n",
        "      url=\"https://europe-west3-aiplatform.googleapis.com/v1/projects/bachelor-thesis-428711/locations/europe-west3/publishers/google/models/multimodalembedding@001:predict\",\n",
        "      json={\n",
        "        \"instances\": [\n",
        "          {\n",
        "            \"image\": {\n",
        "              \"bytesBase64Encoded\": b64img\n",
        "            }\n",
        "          }\n",
        "        ],\n",
        "        \"parameters\": {\n",
        "          \"dimension\": 1408\n",
        "        }\n",
        "      }\n",
        "  )\n",
        "\n",
        "  return response.json()['predictions'][0]['imageEmbedding']"
      ],
      "metadata": {
        "id": "bXKVdrM4c5y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_text_embedding(text):\n",
        "  text = text[:1000]\n",
        "\n",
        "  google_token = !gcloud auth print-access-token\n",
        "  google_token = google_token[0]\n",
        "\n",
        "  response = requests.post(\n",
        "      headers={\n",
        "          \"Authorization\": \"Bearer \" + google_token,\n",
        "          \"Content-Type\": \"application/json\"\n",
        "          },\n",
        "      url=\"https://europe-west3-aiplatform.googleapis.com/v1/projects/bachelor-thesis-428711/locations/europe-west3/publishers/google/models/multimodalembedding@001:predict\",\n",
        "      json={\n",
        "        \"instances\": [\n",
        "          {\n",
        "            \"text\": text\n",
        "          }\n",
        "        ],\n",
        "        \"parameters\": {\n",
        "          \"dimension\": 1408\n",
        "        }\n",
        "      }\n",
        "  )\n",
        "\n",
        "  return response.json()['predictions'][0]['textEmbedding']"
      ],
      "metadata": {
        "id": "Jfe6YAS0dOQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pymongo\n",
        "import requests\n",
        "from google.colab import userdata\n",
        "\n",
        "from pydrive2.auth import GoogleAuth\n",
        "from pydrive2.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "metadata": {
        "id": "vOMiVa76SlsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mongo_client = pymongo.MongoClient(userdata.get('CLUSTER_BACHELOR_CLUSTER_CONNECTION_STRING'))\n",
        "\n",
        "db = mongo_client[\"approach-1-new\"]\n",
        "collection = db[\"embeddings\"]"
      ],
      "metadata": {
        "id": "r9LTaYx1SrX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "gdrive = GoogleDrive(gauth)"
      ],
      "metadata": {
        "id": "ODwRjOUNSukd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_images_folder = gdrive.ListFile({'q': \"mimeType = 'application/vnd.google-apps.folder' and title = 'output-images'\" }).GetList()[0]\n",
        "\n",
        "output_images_files = gdrive.ListFile({'q': \"'\"+ output_images_folder['id'] + \"' in parents and fileExtension = 'png'\"}).GetList()"
      ],
      "metadata": {
        "id": "Zh-ehvbvSxTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_list = []\n",
        "\n",
        "for file in output_images_files:\n",
        "  file.InsertPermission({\n",
        "      'type': 'anyone',\n",
        "      'value': 'anyone',\n",
        "      'role': 'reader'\n",
        "  })\n",
        "  image_url = \"https://drive.usercontent.google.com/download?id=\" + file['id'] + \"&authuser=0\"\n",
        "  #response = requests.get(image_url)\n",
        "  #embedding = get_features(response.content)\n",
        "  embedding = get_image_embedding(image_url)\n",
        "  data_list.append({\"embedding\": embedding, \"url\": image_url})"
      ],
      "metadata": {
        "id": "7wDaHcnKS17y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "collection.insert_many(data_list)"
      ],
      "metadata": {
        "id": "kfEtfqSTTAul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrieve image for text query (similarity search):"
      ],
      "metadata": {
        "id": "cSNpv-YFwOn9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What are the ESG targets?\"\n",
        "\n",
        "embedded_query = get_text_embedding(query)\n",
        "len(embedded_query)"
      ],
      "metadata": {
        "id": "IPAUNfnAdXxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_similar_images(query):\n",
        "  embedded_query = get_text_embedding(query)\n",
        "\n",
        "  similarity_search_pipeline = [\n",
        "    {\n",
        "      '$vectorSearch': {\n",
        "        'index': 'approach_1_index',\n",
        "        'path': 'embedding',\n",
        "        'queryVector': embedded_query,\n",
        "        'numCandidates': 150,\n",
        "        'limit': 5\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"$project\": {\n",
        "        \"_id\": 0,\n",
        "        \"embedding\": 1,\n",
        "        \"url\": 1,\n",
        "        \"score\": { \"$meta\": \"vectorSearchScore\" }\n",
        "      }\n",
        "    }\n",
        "  ]\n",
        "\n",
        "  result = db.embeddings.aggregate(similarity_search_pipeline)\n",
        "\n",
        "  url_list = []\n",
        "  for image in result:\n",
        "    url_list.append(image['url'])\n",
        "\n",
        "  return url_list"
      ],
      "metadata": {
        "id": "Sd6c-FPnfhbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_similar_images(query)"
      ],
      "metadata": {
        "id": "gR7cB8pnVUTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.prompts.chat import MessagesPlaceholder\n",
        "from langchain_core.messages.system import SystemMessage\n",
        "from langchain_core.messages.human import HumanMessage\n",
        "\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "llm = ChatOpenAI(api_key=OPENAI_API_KEY, model=\"gpt-4o\")\n",
        "\n",
        "def get_answer(query):\n",
        "  similar_images = get_similar_images(query)\n",
        "\n",
        "  image_prompt_text = []\n",
        "  for url in similar_images:\n",
        "    image_prompt_text.append({\"type\": \"image_url\", \"image_url\": {\"url\": url}})\n",
        "\n",
        "  image_prompt_text.append({\"type\": \"text\", \"text\": \"Based on the information in the images, answer the question: {question}\"})\n",
        "\n",
        "  prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a powerful visual assistant who can answer questions based on information in the given images.\"),\n",
        "    (\"human\", image_prompt_text)\n",
        "  ])\n",
        "\n",
        "  llm_chain = prompt | llm\n",
        "  try:\n",
        "    result = llm_chain.invoke(query).content\n",
        "  except:\n",
        "    print(\"Error while sending query to LLM\")\n",
        "    result = get_answer(query)\n",
        "\n",
        "  return result"
      ],
      "metadata": {
        "id": "XVIUSObit8pa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from rouge_score import rouge_scorer\n",
        "from bert_score import score\n",
        "\n",
        "def create_scores():\n",
        "  df_bleu = pd.read_csv(\"/content/drive/MyDrive/bachelor-thesis/results/bleu.csv\")\n",
        "  df_rouge1 = pd.read_csv(\"/content/drive/MyDrive/bachelor-thesis/results/rouge-1.csv\")\n",
        "  df_rouge2 = pd.read_csv(\"/content/drive/MyDrive/bachelor-thesis/results/rouge-2.csv\")\n",
        "  df_rougel = pd.read_csv(\"/content/drive/MyDrive/bachelor-thesis/results/rouge-l.csv\")\n",
        "  df_bertscore = pd.read_csv(\"/content/drive/MyDrive/bachelor-thesis/results/bertscore.csv\")\n",
        "\n",
        "  for i, question in enumerate(df_bleu[\"question\"]):\n",
        "    if i >= 50:\n",
        "      break\n",
        "\n",
        "    while(True):\n",
        "      print(\"Question \" + str(i))\n",
        "      try:\n",
        "        answer = get_answer(question)\n",
        "      except:\n",
        "        print(\"Error in getting answer. Trying again\")\n",
        "        continue\n",
        "      break\n",
        "\n",
        "    df_bleu[\"approach-1-text\"][i] = answer\n",
        "    df_rouge1[\"approach-1-text\"][i] = answer\n",
        "    df_rouge2[\"approach-1-text\"][i] = answer\n",
        "    df_rougel[\"approach-1-text\"][i] = answer\n",
        "    df_bertscore[\"approach-1-text\"][i] = answer\n",
        "\n",
        "    split_answer = answer.split()\n",
        "\n",
        "    reference_answer = df_bleu[\"reference-text\"][i]\n",
        "    split_reference_answer = reference_answer.split()\n",
        "\n",
        "    bleu_score = sentence_bleu([split_reference_answer], split_answer)\n",
        "\n",
        "    _rouge_scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeLsum'], use_stemmer=True)\n",
        "    rouge_scores = _rouge_scorer.score(reference_answer, answer)\n",
        "\n",
        "    rouge1 = rouge_scores['rouge1'].precision\n",
        "    rouge2 = rouge_scores['rouge2'].precision\n",
        "    rougeLsum = rouge_scores['rougeLsum'].precision\n",
        "\n",
        "    bertscore_tensor, _, _ = score(cands=[answer], refs=[reference_answer], lang=\"en\")\n",
        "    bertscore = bertscore_tensor.numpy()[0]\n",
        "\n",
        "\n",
        "    df_bleu[\"approach-1-score\"][i] = bleu_score\n",
        "    df_rouge1['approach-1-score'][i] = rouge1\n",
        "    df_rouge2['approach-1-score'][i] = rouge2\n",
        "    df_rougel['approach-1-score'][i] = rougeLsum\n",
        "    df_bertscore['approach-1-score'][i] = bertscore\n",
        "\n",
        "    df_bleu.to_csv(\"/content/drive/MyDrive/bachelor-thesis/results/bleu.csv\")\n",
        "    df_rouge1.to_csv(\"/content/drive/MyDrive/bachelor-thesis/results/rouge-1.csv\")\n",
        "    df_rouge2.to_csv(\"/content/drive/MyDrive/bachelor-thesis/results/rouge-2.csv\")\n",
        "    df_rougel.to_csv(\"/content/drive/MyDrive/bachelor-thesis/results/rouge-l.csv\")\n",
        "    df_bertscore.to_csv(\"/content/drive/MyDrive/bachelor-thesis/results/bertscore.csv\")\n",
        "\n"
      ],
      "metadata": {
        "id": "x6V4nU9PtWWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_scores()"
      ],
      "metadata": {
        "id": "w2UzrYSxFhI0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}