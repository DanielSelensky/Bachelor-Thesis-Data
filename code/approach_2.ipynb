{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FL_6rFu571b7"
      },
      "outputs": [],
      "source": [
        "!pip install PyMuPDF\n",
        "!pip install pymongo\n",
        "!pip install PyDrive2\n",
        "!pip install OpenAI\n",
        "!pip install pytesseract\n",
        "!pip install bert-score\n",
        "!pip install rouge-score\n",
        "!sudo apt install tesseract-ocr tesseract-ocr-deu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2B5M8a9qFSR"
      },
      "outputs": [],
      "source": [
        "!pip install langchain langchain_community langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMm6MeCR-hO8"
      },
      "outputs": [],
      "source": [
        "import fitz  # PyMuPDF\n",
        "from PIL import Image\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6khrm0K7-kLu"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMynX8y2-lUY"
      },
      "outputs": [],
      "source": [
        "def pdf_to_images(pdf_path, output_folder):\n",
        "    # Open the PDF file\n",
        "    pdf_document = fitz.open(pdf_path)\n",
        "    number_of_pages = pdf_document.page_count\n",
        "\n",
        "    # Loop through each page\n",
        "    for page_num in range(number_of_pages):\n",
        "        # Get the page\n",
        "        page = pdf_document.load_page(page_num)\n",
        "        # Render page to an image\n",
        "        pix = page.get_pixmap(dpi=200)\n",
        "\n",
        "        # Convert to a PIL image\n",
        "        img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
        "\n",
        "        # Save the image\n",
        "        img.save(f\"{output_folder}/page_{page_num + 1}.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GrGN2RO-mR7"
      },
      "outputs": [],
      "source": [
        "pdf_to_images(\"/content/drive/MyDrive/bachelor-thesis/pdfs/01.pdf\", \"/content/drive/MyDrive/bachelor-thesis/output-images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQh2YvzUEOXR"
      },
      "outputs": [],
      "source": [
        "!gcloud init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFyF9KiqDPgE"
      },
      "outputs": [],
      "source": [
        "!gcloud auth application-default login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLr9L9yFTqrM"
      },
      "outputs": [],
      "source": [
        "google_token = !gcloud auth print-access-token\n",
        "google_token = google_token[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wtwlsx7sT4Fk"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import base64\n",
        "import numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_rrxMnDUMJi"
      },
      "outputs": [],
      "source": [
        "def get_image_text_embedding(image_url, text):\n",
        "\n",
        "  b64img = base64.b64encode(requests.get(image_url).content).decode(\"ascii\")\n",
        "\n",
        "  google_token = !gcloud auth print-access-token\n",
        "  google_token = google_token[0]\n",
        "\n",
        "  text = text[:1000]\n",
        "\n",
        "  response = requests.post(\n",
        "      headers={\n",
        "          \"Authorization\": \"Bearer \" + google_token,\n",
        "          \"Content-Type\": \"application/json\"\n",
        "          },\n",
        "      url=\"https://europe-west3-aiplatform.googleapis.com/v1/projects/bachelor-thesis-428711/locations/europe-west3/publishers/google/models/multimodalembedding@001:predict\",\n",
        "      json={\n",
        "        \"instances\": [\n",
        "          {\n",
        "            \"image\": {\n",
        "              \"bytesBase64Encoded\": b64img\n",
        "            },\n",
        "            \"text\": text\n",
        "          }\n",
        "        ],\n",
        "        \"parameters\": {\n",
        "          \"dimension\": 1408\n",
        "        }\n",
        "      }\n",
        "  )\n",
        "\n",
        "  return (numpy.array(response.json()['predictions'][0]['imageEmbedding']) * 0.5 + numpy.array(response.json()['predictions'][0]['textEmbedding']) * 0.5).tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ujI6FWHn2_7"
      },
      "outputs": [],
      "source": [
        "def get_text_embedding(text):\n",
        "  text = text[:1000]\n",
        "\n",
        "  google_token = !gcloud auth print-access-token\n",
        "  google_token = google_token[0]\n",
        "\n",
        "  response = requests.post(\n",
        "      headers={\n",
        "          \"Authorization\": \"Bearer \" + google_token,\n",
        "          \"Content-Type\": \"application/json\"\n",
        "          },\n",
        "      url=\"https://europe-west3-aiplatform.googleapis.com/v1/projects/bachelor-thesis-428711/locations/europe-west3/publishers/google/models/multimodalembedding@001:predict\",\n",
        "      json={\n",
        "        \"instances\": [\n",
        "          {\n",
        "            \"text\": text\n",
        "          }\n",
        "        ],\n",
        "        \"parameters\": {\n",
        "          \"dimension\": 1408\n",
        "        }\n",
        "      }\n",
        "  )\n",
        "\n",
        "  return response.json()['predictions'][0]['textEmbedding']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPsPQXxn_Fb9"
      },
      "outputs": [],
      "source": [
        "import pytesseract\n",
        "import requests\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import io\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def recognize_text(imgurl):\n",
        "  response = requests.get(imgurl)\n",
        "  img = Image.open(io.BytesIO(response.content))\n",
        "\n",
        "  img_array = np.asarray(img)\n",
        "\n",
        "  kernelSize = 5\n",
        "  maxKernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernelSize, kernelSize))\n",
        "  localMax = cv2.morphologyEx(img_array, cv2.MORPH_CLOSE, maxKernel, None, None, 1, cv2.BORDER_REFLECT101)\n",
        "\n",
        "  gainDivision = np.where(localMax == 0, 0, (img_array/localMax))\n",
        "\n",
        "  gainDivision = np.clip((255 * gainDivision), 0, 255)\n",
        "\n",
        "  gainDivision = gainDivision.astype(\"uint8\")\n",
        "\n",
        "  grayscaleImage = cv2.cvtColor(gainDivision, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  _, binaryImage = cv2.threshold(grayscaleImage, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "\n",
        "  text = pytesseract.image_to_string(binaryImage, lang=\"eng+deu\")\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7WRsTG1-xaY"
      },
      "outputs": [],
      "source": [
        "import pymongo\n",
        "import requests\n",
        "from google.colab import userdata\n",
        "\n",
        "from pydrive2.auth import GoogleAuth\n",
        "from pydrive2.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w50vTyGx-zHh"
      },
      "outputs": [],
      "source": [
        "mongo_client = pymongo.MongoClient(userdata.get('CLUSTER_BACHELOR_CLUSTER_CONNECTION_STRING'))\n",
        "\n",
        "db = mongo_client[\"approach-2-new\"]\n",
        "collection = db[\"embeddings\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esMEBFEd-66M"
      },
      "outputs": [],
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuFoF3-w-8Uw"
      },
      "outputs": [],
      "source": [
        "output_images_folder = drive.ListFile({'q': \"mimeType = 'application/vnd.google-apps.folder' and title = 'output-images'\" }).GetList()[0]\n",
        "\n",
        "output_images_files = drive.ListFile({'q': \"'\"+ output_images_folder['id'] + \"' in parents and fileExtension = 'png'\"}).GetList()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSYgzhDA-9UA"
      },
      "outputs": [],
      "source": [
        "data_list = []\n",
        "\n",
        "for file in output_images_files:\n",
        "  '''file.InsertPermission({\n",
        "      'type': 'anyone',\n",
        "      'value': 'anyone',\n",
        "      'role': 'reader'\n",
        "  })'''\n",
        "  image_url = \"https://drive.usercontent.google.com/download?id=\" + file['id'] + \"&authuser=0\"\n",
        "  response = requests.get(image_url)\n",
        "\n",
        "  image_text = recognize_text(image_url)\n",
        "  total_embedding = get_image_text_embedding(image_url, image_text)\n",
        "\n",
        "\n",
        "  data_list.append({\"embedding\": total_embedding, \"url\": image_url, \"text\": image_text})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfEtfqSTTAul"
      },
      "outputs": [],
      "source": [
        "collection.insert_many(data_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSNpv-YFwOn9"
      },
      "source": [
        "Retrieve image for text query (similarity search):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPAUNfnAdXxt"
      },
      "outputs": [],
      "source": [
        "query = \"What are the ESG targets?\"\n",
        "\n",
        "embedded_query = get_text_embedding(query)\n",
        "len(embedded_query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53-BMG88gbEj"
      },
      "outputs": [],
      "source": [
        "def get_similar_images(query):\n",
        "  embedded_query = get_text_embedding(query)\n",
        "\n",
        "  similarity_search_pipeline = [\n",
        "    {\n",
        "      '$vectorSearch': {\n",
        "        'index': 'approach_2_index',\n",
        "        'path': 'embedding',\n",
        "        'queryVector': embedded_query,\n",
        "        'numCandidates': 150,\n",
        "        'limit': 5\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"$project\": {\n",
        "        \"_id\": 0,\n",
        "        \"embedding\": 1,\n",
        "        \"url\": 1,\n",
        "        \"text\": 1,\n",
        "        \"score\": { \"$meta\": \"vectorSearchScore\" }\n",
        "      }\n",
        "    }\n",
        "  ]\n",
        "\n",
        "  result = db.embeddings.aggregate(similarity_search_pipeline)\n",
        "\n",
        "  image_list = []\n",
        "  for image in result:\n",
        "    image_list.append((image['url'], image['text']))\n",
        "\n",
        "  return image_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m12pkjFQgzy8"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.prompts.chat import MessagesPlaceholder\n",
        "from langchain_core.messages.system import SystemMessage\n",
        "from langchain_core.messages.human import HumanMessage\n",
        "\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "llm = ChatOpenAI(api_key=OPENAI_API_KEY, model=\"gpt-4o\")\n",
        "\n",
        "def get_answer(query):\n",
        "  similar_images = get_similar_images(query)\n",
        "  print(similar_images)\n",
        "\n",
        "  image_prompt_text = []\n",
        "  for url, text in similar_images:\n",
        "    b64img = base64.b64encode(requests.get(url).content).decode(\"ascii\")\n",
        "    image_prompt_text.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{b64img}\"}})\n",
        "\n",
        "  inner_text = f\"\\n\\nThe following text is in the images: \\n\"\n",
        "  for url, text in similar_images:\n",
        "    inner_text += f\"{text}\\n\\n\"\n",
        "  inner_text = inner_text.replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
        "\n",
        "  image_prompt_text.append({\"type\": \"text\", \"text\": \"Based on the information in the images and the text in the images, answer the question: {question}\" + inner_text})\n",
        "\n",
        "  prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a powerful visual assistant who can answer questions based on information in the given images.\"),\n",
        "    (\"human\", image_prompt_text)\n",
        "  ])\n",
        "\n",
        "\n",
        "  llm_chain = prompt | llm\n",
        "  result = llm_chain.invoke(query).content\n",
        "\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Or0A_FpwqMNw"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from rouge_score import rouge_scorer\n",
        "from bert_score import score\n",
        "\n",
        "def create_scores():\n",
        "  df_bleu = pd.read_csv(\"/content/drive/MyDrive/bachelor-thesis/results/bleu.csv\")\n",
        "  df_rouge1 = pd.read_csv(\"/content/drive/MyDrive/bachelor-thesis/results/rouge-1.csv\")\n",
        "  df_rouge2 = pd.read_csv(\"/content/drive/MyDrive/bachelor-thesis/results/rouge-2.csv\")\n",
        "  df_rougel = pd.read_csv(\"/content/drive/MyDrive/bachelor-thesis/results/rouge-l.csv\")\n",
        "  df_bertscore = pd.read_csv(\"/content/drive/MyDrive/bachelor-thesis/results/bertscore.csv\")\n",
        "\n",
        "  for i, question in enumerate(df_bleu[\"question\"]):\n",
        "    if i >= 50:\n",
        "      break\n",
        "\n",
        "    while(True):\n",
        "      print(\"Question \" + str(i))\n",
        "      try:\n",
        "        answer = get_answer(question)\n",
        "      except Exception as error:\n",
        "        print(\"Error in getting answer. Trying again. Error:\")\n",
        "        print(error)\n",
        "        continue\n",
        "      break\n",
        "\n",
        "    df_bleu[\"approach-2-text\"][i] = answer\n",
        "    df_rouge1[\"approach-2-text\"][i] = answer\n",
        "    df_rouge2[\"approach-2-text\"][i] = answer\n",
        "    df_rougel[\"approach-2-text\"][i] = answer\n",
        "    df_bertscore[\"approach-2-text\"][i] = answer\n",
        "\n",
        "    split_answer = answer.split()\n",
        "\n",
        "    reference_answer = df_bleu[\"reference-text\"][i]\n",
        "    split_reference_answer = reference_answer.split()\n",
        "\n",
        "    bleu_score = sentence_bleu([split_reference_answer], split_answer)\n",
        "\n",
        "    _rouge_scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeLsum'], use_stemmer=True)\n",
        "    rouge_scores = _rouge_scorer.score(reference_answer, answer)\n",
        "\n",
        "    rouge1 = rouge_scores['rouge1'].precision\n",
        "    rouge2 = rouge_scores['rouge2'].precision\n",
        "    rougeLsum = rouge_scores['rougeLsum'].precision\n",
        "\n",
        "    bertscore_tensor, _, _ = score(cands=[answer], refs=[reference_answer], lang=\"en\")\n",
        "    bertscore = bertscore_tensor.numpy()[0]\n",
        "\n",
        "\n",
        "    df_bleu[\"approach-2-score\"][i] = bleu_score\n",
        "    df_rouge1['approach-2-score'][i] = rouge1\n",
        "    df_rouge2['approach-2-score'][i] = rouge2\n",
        "    df_rougel['approach-2-score'][i] = rougeLsum\n",
        "    df_bertscore['approach-2-score'][i] = bertscore\n",
        "\n",
        "  df_bleu.to_csv(\"/content/drive/MyDrive/bachelor-thesis/results/bleu.csv\")\n",
        "  df_rouge1.to_csv(\"/content/drive/MyDrive/bachelor-thesis/results/rouge-1.csv\")\n",
        "  df_rouge2.to_csv(\"/content/drive/MyDrive/bachelor-thesis/results/rouge-2.csv\")\n",
        "  df_rougel.to_csv(\"/content/drive/MyDrive/bachelor-thesis/results/rouge-l.csv\")\n",
        "  df_bertscore.to_csv(\"/content/drive/MyDrive/bachelor-thesis/results/bertscore.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ga6vxGjIq_Sb"
      },
      "outputs": [],
      "source": [
        "create_scores()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}